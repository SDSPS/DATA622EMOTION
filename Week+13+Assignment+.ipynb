{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6711\n",
      "(6711L, 1024L)\n",
      "(6711L,)\n",
      "('X_train shape:', (5368L, 1L, 32L, 32L))\n",
      "(5368L, 'train samples')\n",
      "(1343L, 'test samples')\n",
      "('label : ', array([ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.]))\n",
      "Train on 5368 samples, validate on 1343 samples\n",
      "Epoch 1/6\n",
      "5368/5368 [==============================] - 184s - loss: 1.0956 - acc: 0.5047 - val_loss: 1.2052 - val_acc: 0.5212\n",
      "Epoch 2/6\n",
      "5368/5368 [==============================] - 196s - loss: 1.0430 - acc: 0.5183 - val_loss: 1.0539 - val_acc: 0.5212\n",
      "Epoch 3/6\n",
      "5368/5368 [==============================] - 199s - loss: 0.9888 - acc: 0.5700 - val_loss: 0.9662 - val_acc: 0.7148\n",
      "Epoch 4/6\n",
      "5368/5368 [==============================] - 201s - loss: 0.8248 - acc: 0.7090 - val_loss: 0.7676 - val_acc: 0.7550\n",
      "Epoch 5/6\n",
      "5368/5368 [==============================] - 210s - loss: 0.7308 - acc: 0.7465 - val_loss: 0.6864 - val_acc: 0.7565\n",
      "Epoch 6/6\n",
      "5368/5368 [==============================] - 209s - loss: 0.6780 - acc: 0.7778 - val_loss: 0.6773 - val_acc: 0.7602\n",
      "Train on 4294 samples, validate on 1074 samples\n",
      "Epoch 1/6\n",
      "4294/4294 [==============================] - 194s - loss: 0.6508 - acc: 0.7820 - val_loss: 0.5726 - val_acc: 0.8240\n",
      "Epoch 2/6\n",
      "4294/4294 [==============================] - 177s - loss: 0.6242 - acc: 0.7920 - val_loss: 0.5438 - val_acc: 0.8203\n",
      "Epoch 3/6\n",
      "4294/4294 [==============================] - 192s - loss: 0.6155 - acc: 0.7927 - val_loss: 0.5714 - val_acc: 0.8250\n",
      "Epoch 4/6\n",
      "4294/4294 [==============================] - 185s - loss: 0.5998 - acc: 0.7955 - val_loss: 0.5387 - val_acc: 0.8268\n",
      "Epoch 5/6\n",
      "4294/4294 [==============================] - 184s - loss: 0.5891 - acc: 0.8020 - val_loss: 0.5357 - val_acc: 0.8222\n",
      "Epoch 6/6\n",
      "4294/4294 [==============================] - 194s - loss: 0.5723 - acc: 0.8079 - val_loss: 0.5381 - val_acc: 0.8268\n",
      "[u'seaborn-darkgrid', u'seaborn-notebook', u'classic', u'seaborn-ticks', u'grayscale', u'bmh', u'seaborn-talk', u'dark_background', u'ggplot', u'fivethirtyeight', u'seaborn-colorblind', u'seaborn-deep', u'seaborn-whitegrid', u'seaborn-bright', u'seaborn-poster', u'seaborn-muted', u'seaborn-paper', u'seaborn-white', u'seaborn-pastel', u'seaborn-dark', u'seaborn-dark-palette']\n",
      "('Test score:', 1.0445039550137893)\n",
      "('Test accuracy:', 0.52122114668652275)\n",
      "8/8 [==============================] - 0s\n",
      "[5 5 5 5 5 5 5 5]\n",
      "[[ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]]\n",
      "[[  1.45810535e-02   1.88389688e-03   1.25798467e-03 ...,   2.89082807e-02\n",
      "    2.64745559e-05   2.26675766e-05]\n",
      " [  1.45370485e-02   1.86659838e-03   1.24514254e-03 ...,   2.88571138e-02\n",
      "    2.60272245e-05   2.22792987e-05]\n",
      " [  1.45634534e-02   1.87167851e-03   1.25010766e-03 ...,   2.89061666e-02\n",
      "    2.61565147e-05   2.23873230e-05]\n",
      " ..., \n",
      " [  1.45208789e-02   1.86756847e-03   1.24519633e-03 ...,   2.87132878e-02\n",
      "    2.60814377e-05   2.23127208e-05]\n",
      " [  1.45189213e-02   1.86572352e-03   1.24344206e-03 ...,   2.86745522e-02\n",
      "    2.60539455e-05   2.22904127e-05]\n",
      " [  1.44906370e-02   1.85587234e-03   1.23630825e-03 ...,   2.86184642e-02\n",
      "    2.57964257e-05   2.20668735e-05]]\n",
      "[5 5 5 ..., 5 5 5]\n",
      "1343/1343 [==============================] - 14s    \n",
      "[5 5 5 ..., 5 5 5]\n",
      "1343/1343 [==============================] - 13s    \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "    class 0(Anger)       0.00      0.00      0.00        25\n",
      " class 1(Contempt)       0.00      0.00      0.00         3\n",
      "  class 2(Disgust)       0.00      0.00      0.00         7\n",
      "     class 3(Fear)       0.00      0.00      0.00         9\n",
      "class 4(Happiness)       0.00      0.00      0.00       534\n",
      "  class 5(Nuetral)       0.52      1.00      0.69       700\n",
      "   class6(Sadness)       0.00      0.00      0.00        25\n",
      " class 7(Surprise)       0.00      0.00      0.00        40\n",
      "\n",
      "       avg / total       0.27      0.52      0.36      1343\n",
      "\n",
      "[[  0   0   0   0   0  25   0   0]\n",
      " [  0   0   0   0   0   3   0   0]\n",
      " [  0   0   0   0   0   7   0   0]\n",
      " [  0   0   0   0   0   9   0   0]\n",
      " [  0   0   0   0   0 534   0   0]\n",
      " [  0   0   0   0   0 700   0   0]\n",
      " [  0   0   0   0   0  25   0   0]\n",
      " [  0   0   0   0   0  40   0   0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# saving weights\\n\\nfname = \"weights-Test-CNN.hdf5\"\\nmodel.save_weights(fname,overwrite=True)\\n\\n\\n\\n# Loading weights\\n\\nfname = \"weights-Test-CNN.hdf5\"\\nmodel.load_weights(fname)\\n  '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD,RMSprop,adam\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import os\n",
    "import theano\n",
    "from PIL import Image\n",
    "from numpy import *\n",
    "\n",
    "\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 32,32\n",
    "\n",
    "# number of channels\n",
    "img_channels =1\n",
    "\n",
    "\n",
    "#  data\n",
    "\n",
    "path1 = 'C:/Users/dundeva/Documents/CroppedImages'    #path of folder of images    \n",
    "path2 = 'C:/Users/dundeva/Documents/AugmentedImages/data/train'  #path of folder to save images    \n",
    "\n",
    "listing = os.listdir(path1) \n",
    "num_samples=size(listing)\n",
    "print num_samples\n",
    "\n",
    "\n",
    "for file in listing:\n",
    "    im = Image.open(path1 + '//' + file)   \n",
    "    img = im.resize((img_rows,img_cols))\n",
    "    gray = img.convert('L')\n",
    "                #need to do some more processing here           \n",
    "    gray.save(path2 +'//' +  file, \"JPEG\")\n",
    "\n",
    "imlist = os.listdir(path1)\n",
    "\n",
    "im1 = array(Image.open('C:/Users/dundeva/Documents/AugmentedImages/data/train' + '//'+ imlist[0])) # open one image to get size\n",
    "m,n = im1.shape[0:2] # get the size of the images\n",
    "imnbr = len(imlist) # get the number of images\n",
    "\n",
    "# create matrix to store all flattened images\n",
    "immatrix = array([array(Image.open('C:/Users/dundeva/Documents/AugmentedImages/data/train'+ '//' + im2)).flatten()\n",
    "              for im2 in imlist],'f')\n",
    "                \n",
    "label=np.ones((num_samples,),dtype = int)\n",
    "label[0:129]=0#Anger\n",
    "label[129:136]=1#Contempt\n",
    "label[136:168]=2#Disgust\n",
    "label[168:211]=3#Fear\n",
    "label[211:2812]=4#Happiness\n",
    "label[2812:6393]=5#Nuetral\n",
    "label[6393:6505]=6#Sadness\n",
    "label[6505:6704]=7#Surprise\n",
    "\n",
    "\n",
    "data,Label = shuffle(immatrix,label, random_state=2)\n",
    "train_data = [data,Label]\n",
    "\n",
    "img=immatrix[167].reshape(img_rows,img_cols)\n",
    "plt.imshow(img)\n",
    "plt.imshow(img,cmap='gray')\n",
    "print (train_data[0].shape)\n",
    "print (train_data[1].shape)\n",
    "\n",
    "\n",
    "\n",
    "#batch_size to train\n",
    "batch_size = 32\n",
    "# number of output classes\n",
    "nb_classes =10\n",
    "# number of epochs to train\n",
    "nb_epoch =6\n",
    "data_augmentation = True\n",
    "\n",
    "# number of convolutional filters to use\n",
    "nb_filters = 32\n",
    "# size of pooling area for max pooling\n",
    "nb_pool = 3\n",
    "# convolution kernel size\n",
    "nb_conv = 3\n",
    "\n",
    "(X, y) = (train_data[0],train_data[1])\n",
    "\n",
    "\n",
    "# split X and y into training and testing sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4)\n",
    "\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "'''\n",
    "i = 100\n",
    "plt.imshow(X_train[i, 0], interpolation='nearest')\n",
    "print(\"label : \", Y_train[i,:])\n",
    "'''\n",
    "'''if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(X_train, Y_train,\n",
    "              batch_size=batch_size,\n",
    "              nb_epoch=nb_epoch,\n",
    "              validation_data=(X_test, Y_test),\n",
    "              shuffle=True)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "\n",
    "    # this will do preprocessing and realtime data augmentation\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "    # compute quantities required for featurewise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied)\n",
    "    datagen.fit(X_train)\n",
    "\n",
    "    # fit the model on the batches generated by datagen.flow()\n",
    "    model.fit_generator(datagen.flow(X_train, Y_train,\n",
    "                        batch_size=batch_size),\n",
    "                        samples_per_epoch=X_train.shape[0],\n",
    "                        nb_epoch=nb_epoch,\n",
    "                        validation_data=(X_test, Y_test))\n",
    "'''\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(32, 4, 4, border_mode='same',input_shape=X_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(32, 4, 4))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3, border_mode='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "#sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adadelta',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "hist = model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "              show_accuracy=True, verbose=1, validation_data=(X_test, Y_test))\n",
    "            \n",
    "            \n",
    "hist = model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "              show_accuracy=True, verbose=1, validation_split=0.2)\n",
    "\n",
    "\n",
    "# visualizing losses and accuracy\n",
    "\n",
    "train_loss=hist.history['loss']\n",
    "val_loss=hist.history['val_loss']\n",
    "train_acc=hist.history['acc']\n",
    "val_acc=hist.history['val_acc']\n",
    "xc=range(nb_epoch)\n",
    "\n",
    "plt.figure(1,figsize=(7,5))\n",
    "plt.plot(xc,train_loss)\n",
    "plt.plot(xc,val_loss)\n",
    "plt.xlabel('num of Epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.title('train_loss vs val_loss')\n",
    "plt.grid(True)\n",
    "plt.legend(['train','val'])\n",
    "print plt.style.available # use bmh, classic,ggplot for big pictures\n",
    "plt.style.use(['classic'])\n",
    "\n",
    "plt.figure(2,figsize=(7,5))\n",
    "plt.plot(xc,train_acc)\n",
    "plt.plot(xc,val_acc)\n",
    "plt.xlabel('num of Epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('train_acc vs val_acc')\n",
    "plt.grid(True)\n",
    "plt.legend(['train','val'],loc=4)\n",
    "#print plt.style.available # use bmh, classic,ggplot for big pictures\n",
    "plt.style.use(['classic'])\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "\n",
    "\n",
    "#%%       \n",
    "\n",
    "score = model.evaluate(X_test, Y_test, show_accuracy=True, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "print(model.predict_classes(X_test[1:9]))\n",
    "print(Y_test[1:9])\n",
    "\n",
    "\n",
    "\n",
    "# Confusion Matrix\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "print(Y_pred)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print(y_pred)\n",
    "  \n",
    "'''                     # (or)\n",
    "'''\n",
    "y_pred = model.predict_classes(X_test)\n",
    "print(y_pred)\n",
    "\n",
    "p=model.predict_proba(X_test) # to predict probability\n",
    "\n",
    "target_names = ['class 0(Anger)', 'class 1(Contempt)', 'class 2(Disgust)','class 3(Fear)',\n",
    "                'class 4(Happiness)', 'class 5(Nuetral)', 'class6(Sadness)', 'class 7(Surprise)']\n",
    "print(classification_report(np.argmax(Y_test,axis=1), y_pred,target_names=target_names))\n",
    "print(confusion_matrix(np.argmax(Y_test,axis=1), y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
